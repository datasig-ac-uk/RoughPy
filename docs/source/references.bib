
@misc{kidger_neural_2020,
	title = {Neural {Controlled} {Differential} {Equations} for {Irregular} {Time} {Series}},
	url = {http://arxiv.org/abs/2005.08926},
	doi = {10.48550/arXiv.2005.08926},
	abstract = {Neural ordinary differential equations are an attractive option for modelling temporal dynamics. However, a fundamental issue is that the solution to an ordinary differential equation is determined by its initial condition, and there is no mechanism for adjusting the trajectory based on subsequent observations. Here, we demonstrate how this may be resolved through the well-understood mathematics of {\textbackslash}emph\{controlled differential equations\}. The resulting {\textbackslash}emph\{neural controlled differential equation\} model is directly applicable to the general setting of partially-observed irregularly-sampled multivariate time series, and (unlike previous work on this problem) it may utilise memory-efficient adjoint-based backpropagation even across observations. We demonstrate that our model achieves state-of-the-art performance against similar (ODE or RNN based) models in empirical studies on a range of datasets. Finally we provide theoretical results demonstrating universal approximation, and that our model subsumes alternative ODE models.},
	urldate = {2023-12-08},
	publisher = {arXiv},
	author = {Kidger, Patrick and Morrill, James and Foster, James and Lyons, Terry},
	month = nov,
	year = {2020},
	note = {arXiv:2005.08926 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted at NeurIPS 2020 (Spotlight)},
	file = {arXiv Fulltext PDF:/Users/philipparubin/Zotero/storage/LBFDLT8N/Kidger et al. - 2020 - Neural Controlled Differential Equations for Irreg.pdf:application/pdf;arXiv.org Snapshot:/Users/philipparubin/Zotero/storage/Z8BDTHV7/2005.html:text/html},
}

@misc{lyons_signature_2024,
	title = {Signature {Methods} in {Machine} {Learning}},
	url = {http://arxiv.org/abs/2206.14674},
	abstract = {Signature-based techniques give mathematical insight into the interactions between complex streams of evolving data. These insights can be quite naturally translated into numerical approaches to understanding streamed data, and perhaps because of their mathematical precision, have proved useful in analysing streamed data in situations where the data is irregular, and not stationary, and the dimension of the data and the sample sizes are both moderate. Understanding streamed multi-modal data is exponential: a word in \$n\$ letters from an alphabet of size \$d\$ can be any one of \$d{\textasciicircum}n\$ messages. Signatures remove the exponential amount of noise that arises from sampling irregularity, but an exponential amount of information still remain. This survey aims to stay in the domain where that exponential scaling can be managed directly. Scalability issues are an important challenge in many problems but would require another survey article and further ideas. This survey describes a range of contexts where the data sets are small enough to remove the possibility of massive machine learning, and the existence of small sets of context free and principled features can be used effectively. The mathematical nature of the tools can make their use intimidating to non-mathematicians. The examples presented in this article are intended to bridge this communication gap and provide tractable working examples drawn from the machine learning context. Notebooks are available online for several of these examples. This survey builds on the earlier paper of Ilya Chevryev and Andrey Kormilitzin which had broadly similar aims at an earlier point in the development of this machinery. This article illustrates how the theoretical insights offered by signatures are simply realised in the analysis of application data in a way that is largely agnostic to the data type.},
	urldate = {2024-02-14},
	publisher = {arXiv},
	author = {Lyons, Terry and McLeod, Andrew D.},
	month = jan,
	year = {2024},
	note = {arXiv:2206.14674 [cs, math, stat]},
	keywords = {60L10, 93C15, 68Q32, 34F05, Computer Science - Machine Learning, Mathematics - Classical Analysis and ODEs, Mathematics - Numerical Analysis, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology},
	file = {arXiv.org Snapshot:/Users/philipparubin/Zotero/storage/WN72DE2A/2206.html:text/html;Full Text PDF:/Users/philipparubin/Zotero/storage/6JPHJZZ3/Lyons and McLeod - 2024 - Signature Methods in Machine Learning.pdf:application/pdf},
}

@book{lyons_differential_2007,
	title = {Differential {Equations} {Driven} by {Rough} {Paths}: {Ecole} d’{Eté} de {Probabilités} de {Saint}-{Flour} {XXXIV}-2004},
	isbn = {978-3-540-71285-5},
	shorttitle = {Differential {Equations} {Driven} by {Rough} {Paths}},
	abstract = {Each year young mathematicians congregate in Saint Flour, France, and listen to extended lecture courses on new topics in Probability Theory.   The goal of these notes, representing a course given by Terry Lyons in 2004, is to provide a straightforward and self supporting but minimalist account of the key results forming the foundation of the theory of rough paths. The proofs are similar to those in the existing literature, but have been refined with the benefit of hindsight. The theory of rough paths aims to create the appropriate mathematical framework for expressing the relationships between evolving systems, by extending classical calculus to the natural models for noisy evolving systems, which are often far from differentiable.},
	language = {en},
	publisher = {Springer},
	author = {Lyons, Terry J. and Caruana, Michael J. and Lévy, Thierry},
	month = apr,
	year = {2007},
	note = {Google-Books-ID: hOm5BQAAQBAJ},
	keywords = {Mathematics / Calculus, Mathematics / Differential Equations / General, Mathematics / Mathematical Analysis, Mathematics / Probability \& Statistics / General},
}

@book{bourbaki_algebra_1998,
	title = {Algebra {I}: {Chapters} 1-3},
	isbn = {978-3-540-64243-5},
	shorttitle = {Algebra {I}},
	abstract = {This softcover reprint of the 1974 English translation of the first three chapters of Bourbaki’s Algebre gives a thorough exposition of the fundamentals of general, linear, and multilinear algebra. The first chapter introduces the basic objects, such as groups and rings. The second chapter studies the properties of modules and linear maps, and the third chapter discusses algebras, especially tensor algebras.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Bourbaki, N.},
	month = aug,
	year = {1998},
	note = {Google-Books-ID: STS9aZ6F204C},
	keywords = {Mathematics / Algebra / Abstract, Mathematics / Algebra / General, Mathematics / Algebra / Linear, Mathematics / Calculus, Mathematics / Essays, Mathematics / Functional Analysis, Mathematics / Geometry / General, Mathematics / Group Theory, Mathematics / Mathematical Analysis, Mathematics / Probability \& Statistics / General, Mathematics / Topology, Mathematics / Transformations, Medical / General},
}

@book{reutenauer_free_1993,
	title = {Free {Lie} {Algebras}},
	isbn = {978-0-19-853679-6},
	abstract = {This much-needed new book is the first to specifically detail free Lie algebras. Lie polynomials appeared at the turn of the century and were identified with the free Lie algebra by Magnus and Witt some thirty years later. Many recent, important developments have occurred in the field--especially from the point of view of representation theory--that have necessitated a thorough treatment of the subject. This timely book covers all aspects of the field, including characterization of Lie polynomials and Lie series, subalgebras and automorphisms, canonical projections, Hall bases, shuffles and subwords, circular words, Lie representations of the symmetric group, related symmetric functions, descent algebra, and quasisymmetric functions. With its emphasis on the algebraic and combinatorial point of view as well as representation theory, this book will be welcomed by students and researchers in mathematics and theoretical computer science.},
	language = {en},
	publisher = {Clarendon Press},
	author = {Reutenauer, Christophe},
	year = {1993},
	note = {Google-Books-ID: cBvvAAAAMAAJ},
	keywords = {Mathematics / Algebra / Abstract, Mathematics / Algebra / General, Mathematics / Discrete Mathematics},
}

@book{bourbaki_lie_1989,
	title = {Lie {Groups} and {Lie} {Algebras}: {Chapters} 1-3},
	isbn = {978-3-540-64242-8},
	shorttitle = {Lie {Groups} and {Lie} {Algebras}},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Bourbaki, Nicolas},
	year = {1989},
	note = {Google-Books-ID: brSYF\_rB2ZcC},
}
